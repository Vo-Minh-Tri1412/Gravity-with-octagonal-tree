@misc{kingma2022autoencodingvariationalbayes,
      title={Auto-Encoding Variational Bayes}, 
      author={Diederik P Kingma and Max Welling},
      year={2022},
      eprint={1312.6114},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1312.6114}, 
}

@Article{electronics11213470,
AUTHOR = {Aljohani, Abeer and Alharbe, Nawaf},
TITLE = {Generating Synthetic Images for Healthcare with Novel Deep Pix2Pix GAN},
JOURNAL = {Electronics},
VOLUME = {11},
YEAR = {2022},
NUMBER = {21},
ARTICLE-NUMBER = {3470},
URL = {https://www.mdpi.com/2079-9292/11/21/3470},
ISSN = {2079-9292},
ABSTRACT = {Due to recent developments in deep learning and artificial intelligence, the healthcare industry is currently going through a significant upheaval. Despite a considerable advance in medical imaging and diagnostics, the healthcare industry still has a lot of unresolved problems and unexplored applications. The transmission of a huge number of medical images in particular is a difficult and time-consuming problem. In addition, obtaining new medical images is too expensive. To tackle these issues, we propose deep pix2pix generative adversarial networks (GAN) for generating synthetic medical images. For the comparison, we implemented CycleGAN, Pix2Pix GAN and Deep Pix2Pix GAN. The result has shown that our proposed approach can generate a new synthetic medical image from a different image with more accuracy than that of the other models. To provide a robust model, we trained and evaluated our models on a widely used brain image dataset, the IXI Dataset.},
DOI = {10.3390/electronics11213470}
}

@article{10.1002/wcms.1603, author = {Wigh, D. and Goodman, J. M. and Lapkin, A. A.}, title = {A review of molecular representation in the age of machine learning}, journal = {WIREs Computational Molecular Science}, year = {2022}, volume = {12}, issue = {5}, doi = {10.1002/wcms.1603} }

@Article{JCST-2309-13814,
title = {A Survey of Multimodal Controllable Diffusion Models},
journal = {Journal of Computer Science and Technology},
volume = {39},
number = {3},
pages = {509-541},
year = {2024},
issn = {1000-9000(Print) /1860-4749(Online)},
doi = {10.1007/s11390-024-3814-0},	
url = {https://jcst.ict.ac.cn/en/article/doi/10.1007/s11390-024-3814-0},
author = {Rui Jiang and Guang-Cong Zheng and Teng Li and Tian-Rui Yang and Jing-Dong Wang and Xi Li}
}

@misc{goodfellow2014generativeadversarialnetworks,
      title={Generative Adversarial Networks}, 
      author={Ian J. Goodfellow and Jean Pouget-Abadie and Mehdi Mirza and Bing Xu and David Warde-Farley and Sherjil Ozair and Aaron Courville and Yoshua Bengio},
      year={2014},
      eprint={1406.2661},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1406.2661}, 
}

@ARTICLE{8411144,
author={Zhang, Han and Xu, Tao and Li, Hongsheng and Zhang, Shaoting and Wang, Xiaogang and Huang, Xiaolei and Metaxas, Dimitris N.},
journal={ IEEE Transactions on Pattern Analysis \& Machine Intelligence },
title={{ StackGAN++: Realistic Image Synthesis with Stacked Generative Adversarial Networks }},
year={2019},
volume={41},
number={08},
ISSN={1939-3539},
pages={1947-1962},
abstract={ Although Generative Adversarial Networks (GANs) have shown remarkable success in various tasks, they still face challenges in generating high quality images. In this paper, we propose Stacked Generative Adversarial Networks (StackGANs) aimed at generating high-resolution photo-realistic images. First, we propose a two-stage generative adversarial network architecture, StackGAN-v1, for text-to-image synthesis. The Stage-I GAN sketches the primitive shape and colors of a scene based on a given text description, yielding low-resolution images. The Stage-II GAN takes Stage-I results and the text description as inputs, and generates high-resolution images with photo-realistic details. Second, an advanced multi-stage generative adversarial network architecture, StackGAN-v2, is proposed for both conditional and unconditional generative tasks. Our StackGAN-v2 consists of multiple generators and multiple discriminators arranged in a tree-like structure; images at multiple scales corresponding to the same scene are generated from different branches of the tree. StackGAN-v2 shows more stable training behavior than StackGAN-v1 by jointly approximating multiple distributions. Extensive experiments demonstrate that the proposed stacked generative adversarial networks significantly outperform other state-of-the-art methods in generating photo-realistic images. },
keywords={Gallium nitride;Generators;Image resolution;Training;Image generation;Task analysis;Computational modeling},
doi={10.1109/TPAMI.2018.2856256},
url = {https://doi.ieeecomputersociety.org/10.1109/TPAMI.2018.2856256},
publisher={IEEE Computer Society},
address={Los Alamitos, CA, USA},
month=aug}

@misc{isola2018imagetoimagetranslationconditionaladversarial,
      title={Image-to-Image Translation with Conditional Adversarial Networks}, 
      author={Phillip Isola and Jun-Yan Zhu and Tinghui Zhou and Alexei A. Efros},
      year={2018},
      eprint={1611.07004},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1611.07004}, 
}

@misc{ledig2017photorealisticsingleimagesuperresolution,
      title={Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network}, 
      author={Christian Ledig and Lucas Theis and Ferenc Huszar and Jose Caballero and Andrew Cunningham and Alejandro Acosta and Andrew Aitken and Alykhan Tejani and Johannes Totz and Zehan Wang and Wenzhe Shi},
      year={2017},
      eprint={1609.04802},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1609.04802}, 
}

@INPROCEEDINGS{9008110,
  author={Yu, Ruiyun and Wang, Xiaoqi and Xie, Xiaohui},
  booktitle={2019 IEEE/CVF International Conference on Computer Vision (ICCV)}, 
  title={VTNFP: An Image-Based Virtual Try-On Network With Body and Clothing Feature Preservation}, 
  year={2019},
  volume={},
  number={},
  pages={10510-10519},
  keywords={Clothing;Image segmentation;Shape;Image generation;Three-dimensional displays;Semantics;Strain},
  doi={10.1109/ICCV.2019.01061}}


@misc{ho2020denoisingdiffusionprobabilisticmodels,
      title={Denoising Diffusion Probabilistic Models}, 
      author={Jonathan Ho and Ajay Jain and Pieter Abbeel},
      year={2020},
      eprint={2006.11239},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2006.11239}, 
}

@misc{rombach2022highresolutionimagesynthesislatent,
      title={High-Resolution Image Synthesis with Latent Diffusion Models}, 
      author={Robin Rombach and Andreas Blattmann and Dominik Lorenz and Patrick Esser and Björn Ommer},
      year={2022},
      eprint={2112.10752},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2112.10752}, 
}

@misc{parmar2023zeroshotimagetoimagetranslation,
      title={Zero-shot Image-to-Image Translation}, 
      author={Gaurav Parmar and Krishna Kumar Singh and Richard Zhang and Yijun Li and Jingwan Lu and Jun-Yan Zhu},
      year={2023},
      eprint={2302.03027},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2302.03027}, 
}

@misc{saharia2021imagesuperresolutioniterativerefinement,
      title={Image Super-Resolution via Iterative Refinement}, 
      author={Chitwan Saharia and Jonathan Ho and William Chan and Tim Salimans and David J. Fleet and Mohammad Norouzi},
      year={2021},
      eprint={2104.07636},
      archivePrefix={arXiv},
      primaryClass={eess.IV},
      url={https://arxiv.org/abs/2104.07636}, 
}

@misc{corso2023diffdockdiffusionstepstwists,
      title={DiffDock: Diffusion Steps, Twists, and Turns for Molecular Docking}, 
      author={Gabriele Corso and Hannes Stärk and Bowen Jing and Regina Barzilay and Tommi Jaakkola},
      year={2023},
      eprint={2210.01776},
      archivePrefix={arXiv},
      primaryClass={q-bio.BM},
      url={https://arxiv.org/abs/2210.01776}, 
}

@misc{xue2024auffusionleveragingpowerdiffusion,
      title={Auffusion: Leveraging the Power of Diffusion and Large Language Models for Text-to-Audio Generation}, 
      author={Jinlong Xue and Yayue Deng and Yingming Gao and Ya Li},
      year={2024},
      eprint={2401.01044},
      archivePrefix={arXiv},
      primaryClass={cs.SD},
      url={https://arxiv.org/abs/2401.01044}, 
}

@misc{jo2025loopholingdiscretediffusiondeterministic,
      title={Loopholing Discrete Diffusion: Deterministic Bypass of the Sampling Wall}, 
      author={Mingyu Jo and Jaesik Yoon and Justin Deschenaux and Caglar Gulcehre and Sungjin Ahn},
      year={2025},
      eprint={2510.19304},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2510.19304}, 
}

@misc{hu2021loralowrankadaptationlarge,
      title={LoRA: Low-Rank Adaptation of Large Language Models}, 
      author={Edward J. Hu and Yelong Shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
      year={2021},
      eprint={2106.09685},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2106.09685}, 
}
